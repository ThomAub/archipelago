#!/usr/bin/env python3
"""
Universal audit for individual MCP tool functions.

Discovers tool functions from mcp_servers/*/tools/*.py, extracts input/output
Pydantic models via inspect, and checks:
  1. Input schema: nullable (X | None) fields have `nullable: true` (Gemini compat)
  2. Output schema: nullable fields use `anyOf` with null (jsonschema compat)
  3. E2E: builds a minimal dict with nullable fields = None, validates via jsonschema
"""
import importlib.util
import inspect
import json
import sys
import traceback
from datetime import date, datetime
from decimal import Decimal
from enum import Enum
from pathlib import Path
from types import NoneType, UnionType
from typing import Annotated, Any, Literal, Union, get_args, get_origin, get_type_hints

import jsonschema
from pydantic import BaseModel, Field, TypeAdapter, create_model
from pydantic.fields import FieldInfo
from pydantic_core import PydanticUndefined

REPO = Path.cwd()


# ── helpers ──────────────────────────────────────────────────────────────────

def is_nullable(tp: Any) -> bool:
    origin = get_origin(tp)
    if origin is Union or type(tp) is UnionType:
        return NoneType in get_args(tp)
    return False


def unwrap_type(tp: Any) -> Any:
    """Strip Optional/Union wrapper to get the inner non-None type."""
    origin = get_origin(tp)
    if origin is Union or type(tp) is UnionType:
        non_none = [a for a in get_args(tp) if a is not NoneType]
        return non_none[0] if non_none else tp
    return tp


def is_decimal_type(tp: Any) -> bool:
    inner = unwrap_type(tp)
    return inner is Decimal


def make_stub(tp: Any, field_info: Any = None) -> Any:
    if tp is None or tp is NoneType:
        return None
    origin = get_origin(tp)
    args = get_args(tp)
    if origin is Union or type(tp) is UnionType:
        non_none = [a for a in args if a is not NoneType]
        return make_stub(non_none[0], field_info) if non_none else None
    if origin is Literal:
        return args[0] if args else "test"
    if tp is str:
        return "test"
    if tp is int:
        val = 1
        if field_info is not None:
            ge = getattr(field_info, "ge", None)
            gt = getattr(field_info, "gt", None)
            if ge is not None and val < ge:
                val = int(ge)
            elif gt is not None and val <= gt:
                val = int(gt) + 1
        return val
    if tp is float:
        val = 1.0
        if field_info is not None:
            ge = getattr(field_info, "ge", None)
            gt = getattr(field_info, "gt", None)
            if ge is not None and val < ge:
                val = float(ge)
            elif gt is not None and val <= gt:
                val = float(gt) + 1.0
        return val
    if tp is bool:
        return False
    if tp is Decimal:
        return "0.00"
    if origin is list:
        return []
    if origin in (dict, None) and tp is dict:
        return {}
    if origin is dict:
        return {}
    if isinstance(tp, type) and issubclass(tp, Enum):
        members = list(tp)
        return members[0].value if members else "test"
    if isinstance(tp, type) and issubclass(tp, BaseModel):
        return build_null_output(tp) or {}
    if isinstance(tp, type) and issubclass(tp, datetime):
        return "2024-01-01T00:00:00"
    if isinstance(tp, type) and issubclass(tp, date):
        return "2024-01-01"
    return "test"


def build_null_output(model_cls: type) -> dict | None:
    try:
        hints = get_type_hints(model_cls)
    except Exception:
        return None
    result = {}
    for name, fi in model_cls.model_fields.items():
        tp = hints.get(name)
        if tp and is_nullable(tp):
            result[name] = None
            continue
        if fi.default is not PydanticUndefined and fi.default is not None:
            val = fi.default
            if isinstance(val, Enum):
                val = val.value
            elif isinstance(val, BaseModel):
                val = json.loads(val.model_dump_json())
            elif isinstance(val, (datetime, date)):
                val = val.isoformat()
            elif isinstance(val, Decimal):
                val = str(val)
            elif is_decimal_type(tp) and isinstance(val, (int, float)):
                val = str(Decimal(val).quantize(Decimal("0.01")))
            result[name] = val
            continue
        if fi.default_factory is not None:
            try:
                val = fi.default_factory()
                if isinstance(val, BaseModel):
                    val = json.loads(val.model_dump_json())
                elif isinstance(val, Enum):
                    val = val.value
                elif isinstance(val, (datetime, date)):
                    val = val.isoformat()
                elif isinstance(val, Decimal):
                    val = str(val)
                result[name] = val
                continue
            except Exception:
                pass
        result[name] = make_stub(tp, fi)

    # Handle @computed_field properties (included in serialization schema as required)
    for name, cf in model_cls.model_computed_fields.items():
        if name in result:
            continue
        tp = cf.return_type
        if tp and is_nullable(tp):
            result[name] = None
        else:
            result[name] = make_stub(tp)

    return result


def coerce_to_schema(data: Any, schema: dict, defs: dict | None = None) -> Any:
    """Recursively coerce dict values to match JSON schema types (string for Decimal, etc.)."""
    if data is None or not isinstance(schema, dict):
        return data
    if defs is None:
        defs = schema.get("$defs", {})
    if "$ref" in schema:
        ref_name = schema["$ref"].split("/")[-1]
        return coerce_to_schema(data, defs.get(ref_name, {}), defs)
    if "anyOf" in schema and isinstance(data, dict):
        for variant in schema["anyOf"]:
            resolved = defs.get(variant["$ref"].split("/")[-1], variant) if "$ref" in variant else variant
            if resolved.get("type") == "object" or "properties" in resolved:
                return coerce_to_schema(data, resolved, defs)
        return data
    if schema.get("type") == "string" and isinstance(data, (int, float, Decimal)):
        return str(data)
    if isinstance(data, (int, float)) and not isinstance(data, bool):
        minimum = schema.get("minimum")
        exclusive_min = schema.get("exclusiveMinimum")
        if minimum is not None and data < minimum:
            data = type(data)(minimum)
        elif exclusive_min is not None and data <= exclusive_min:
            data = type(data)(exclusive_min + 1)
        maximum = schema.get("maximum")
        exclusive_max = schema.get("exclusiveMaximum")
        if maximum is not None and data > maximum:
            data = type(data)(maximum)
        elif exclusive_max is not None and data >= exclusive_max:
            data = type(data)(exclusive_max - 1)
        return data
    if schema.get("type") == "object" and isinstance(data, dict):
        props = schema.get("properties", {})
        for k, v in list(data.items()):
            if k in props:
                data[k] = coerce_to_schema(v, props[k], defs)
        return data
    if schema.get("type") == "array" and isinstance(data, list):
        items_schema = schema.get("items", {})
        return [coerce_to_schema(item, items_schema, defs) for item in data]
    return data


def find_nullable_schema_fields(schema: dict, path: str = "root") -> list[dict]:
    """Walk a JSON schema and tag every property that looks nullable."""
    out: list[dict] = []
    if not isinstance(schema, dict):
        return out
    defs = schema.get("$defs", {})

    def resolve(s: dict) -> dict:
        if "$ref" in s:
            ref_name = s["$ref"].split("/")[-1]
            return defs.get(ref_name, s)
        return s

    for prop_name, raw in schema.get("properties", {}).items():
        p = f"{path}.{prop_name}"
        prop = resolve(raw)
        has_nullable = prop.get("nullable") is True
        has_anyof_null = False
        if "anyOf" in prop:
            for item in prop["anyOf"]:
                ri = resolve(item)
                if ri.get("type") == "null":
                    has_anyof_null = True
                    break
        if has_nullable or has_anyof_null:
            out.append({"path": p, "nullable_true": has_nullable, "anyof_null": has_anyof_null})
        out.extend(find_nullable_schema_fields(prop, p))
        if "anyOf" in prop:
            for item in prop["anyOf"]:
                ri = resolve(item)
                out.extend(find_nullable_schema_fields(ri, p))
    if "items" in schema:
        out.extend(find_nullable_schema_fields(resolve(schema["items"]), f"{path}[]"))
    return out


GEMINI_UNSUPPORTED_KEYS = frozenset({
    "oneOf", "allOf", "format", "additionalProperties",
    "const", "examples", "prefixItems",
    "minItems", "maxItems", "minLength", "maxLength",
    "pattern", "uniqueItems",
})


def find_gemini_unsupported(schema: dict, path: str = "root") -> list[dict]:
    """Walk a JSON schema and find fields/patterns Gemini function calling can't handle."""
    out: list[dict] = []
    if not isinstance(schema, dict):
        return out
    defs = schema.get("$defs", {})

    def resolve(s: dict) -> dict:
        if "$ref" in s:
            ref_name = s["$ref"].split("/")[-1]
            return defs.get(ref_name, s)
        return s

    for key in GEMINI_UNSUPPORTED_KEYS:
        if key in schema:
            out.append({"path": path, "key": key, "value_preview": str(schema[key])[:80]})

    if "$ref" in schema and "$defs" not in schema:
        out.append({"path": path, "key": "$ref (unresolved)", "value_preview": schema["$ref"]})

    for prop_name, raw in schema.get("properties", {}).items():
        p = f"{path}.{prop_name}"
        prop = resolve(raw)
        out.extend(find_gemini_unsupported(prop, p))
        if "anyOf" in raw:
            for item in raw["anyOf"]:
                out.extend(find_gemini_unsupported(resolve(item), p))
        if "oneOf" in raw:
            for item in raw["oneOf"]:
                out.extend(find_gemini_unsupported(resolve(item), p))
        if "allOf" in raw:
            for item in raw["allOf"]:
                out.extend(find_gemini_unsupported(resolve(item), p))

    if "items" in schema:
        out.extend(find_gemini_unsupported(resolve(schema["items"]), f"{path}[]"))

    for def_name, def_schema in defs.items():
        out.extend(find_gemini_unsupported(def_schema, f"$defs.{def_name}"))

    return out


# ── tool discovery ───────────────────────────────────────────────────────────

def setup_sys_path():
    sys.path.insert(0, str(REPO))
    pkgs = REPO / "packages"
    if pkgs.exists():
        for pkg in pkgs.iterdir():
            if pkg.is_dir():
                sys.path.insert(0, str(pkg))
    for srv in (REPO / "mcp_servers").iterdir():
        if srv.is_dir() and srv.name != "__pycache__":
            sys.path.insert(0, str(srv))


def load_module(path: Path, mod_name: str):
    spec = importlib.util.spec_from_file_location(mod_name, path)
    if spec is None or spec.loader is None:
        return None
    mod = importlib.util.module_from_spec(spec)
    sys.modules[mod_name] = mod
    spec.loader.exec_module(mod)
    return mod


def discover_tools_in_server(server_path: Path) -> list[dict]:
    tools_dir = server_path / "tools"
    if not tools_dir.exists():
        return []
    found = []
    seen_names: set[str] = set()

    for py in sorted(tools_dir.glob("*.py")):
        if py.name == "__init__.py":
            continue
        mod_name = f"_audit_mod_{server_path.name}_{py.stem}"
        try:
            mod = load_module(py, mod_name)
        except Exception as exc:
            print(f"  WARN import {py.name}: {exc}")
            continue
        if mod is None:
            continue
        for attr_name in sorted(dir(mod)):
            if attr_name.startswith("_"):
                continue
            obj = getattr(mod, attr_name)
            if not callable(obj):
                continue
            defined_in = getattr(obj, "__module__", None)
            wrapped = getattr(obj, "__wrapped__", None)
            if defined_in != mod_name and wrapped is None:
                continue
            if attr_name in seen_names:
                continue
            seen_names.add(attr_name)
            found.append({"name": attr_name, "func": obj, "file": py.name})
    return found


# ── per-tool audit ───────────────────────────────────────────────────────────

def audit_one(tool: dict) -> dict:
    name = tool["name"]
    func = tool["func"]
    actual = func
    while hasattr(actual, "__wrapped__"):
        actual = actual.__wrapped__

    res = {
        "name": name,
        "file": tool["file"],
        "input_model": None,
        "output_model": None,
        "input_check": "SKIP",
        "output_check": "SKIP",
        "e2e_check": "SKIP",
        "gemini_compat": "SKIP",
        "issues": [],
    }

    try:
        hints = get_type_hints(actual, include_extras=True)
    except Exception as e:
        res["issues"].append(f"type-hints error: {e}")
        return res

    # ── find input model ─────────────────────────────────────────────────
    sig = inspect.signature(actual)
    input_model = None
    for pname, _param in sig.parameters.items():
        if pname in ("self", "cls"):
            continue
        ptype = hints.get(pname)
        if ptype is None:
            continue
        raw_type = ptype
        if get_origin(ptype) is Annotated:
            raw_type = get_args(ptype)[0]
        if isinstance(raw_type, type) and issubclass(raw_type, BaseModel):
            input_model = raw_type
            break

    if input_model is None:
        annotated_fields: dict[str, Any] = {}
        for pname, _param in sig.parameters.items():
            if pname in ("self", "cls"):
                continue
            ptype = hints.get(pname)
            if ptype is None:
                continue
            if get_origin(ptype) is Annotated:
                args = get_args(ptype)
                base_type = args[0]
                field_info = None
                for a in args[1:]:
                    if isinstance(a, FieldInfo):
                        field_info = a
                        break
                if field_info is not None:
                    annotated_fields[pname] = (base_type, field_info)
                else:
                    annotated_fields[pname] = (base_type, ...)
        if annotated_fields:
            try:
                input_model = create_model(f"_Audit_{name}_Input", **annotated_fields)
                res["input_model"] = f"Annotated[{len(annotated_fields)} params]"
            except Exception:
                pass

    if input_model is not None:
        if res["input_model"] is None:
            res["input_model"] = input_model.__name__
        try:
            in_schema = input_model.model_json_schema()
            nf = find_nullable_schema_fields(in_schema)
            bad = [f for f in nf if f["anyof_null"] and not f["nullable_true"]]
            if bad:
                res["input_check"] = "FAIL"
                for b in bad:
                    res["issues"].append(f"INPUT {b['path']}: anyOf+null but no nullable:true")
            else:
                res["input_check"] = "PASS"

            unsupported = find_gemini_unsupported(in_schema)
            if unsupported:
                res["gemini_compat"] = "FAIL"
                for u in unsupported:
                    res["issues"].append(
                        f"GEMINI {u['path']}: unsupported key '{u['key']}'"
                    )
            else:
                res["gemini_compat"] = "PASS"
        except Exception as e:
            res["input_check"] = "ERROR"
            res["issues"].append(f"input schema error: {e}")

    # ── find output model ────────────────────────────────────────────────
    ret = hints.get("return")
    output_model = None
    if ret:
        if get_origin(ret) is Annotated:
            ret = get_args(ret)[0]
        origin = get_origin(ret)
        if origin is Union or type(ret) is UnionType:
            for a in get_args(ret):
                if isinstance(a, type) and issubclass(a, BaseModel):
                    output_model = a
                    break
        elif isinstance(ret, type) and issubclass(ret, BaseModel):
            output_model = ret

    if output_model is not None:
        res["output_model"] = output_model.__name__
        try:
            out_schema = TypeAdapter(output_model).json_schema(mode="serialization")
            nf = find_nullable_schema_fields(out_schema)
            bad = [f for f in nf if f["nullable_true"] and not f["anyof_null"]]
            if bad:
                res["output_check"] = "FAIL"
                for b in bad:
                    res["issues"].append(
                        f"OUTPUT {b['path']}: nullable:true WITHOUT anyOf+null → jsonschema will reject None"
                    )
            else:
                res["output_check"] = "PASS"

            # E2E
            try:
                data = build_null_output(output_model)
                if data is not None:
                    coerce_to_schema(data, out_schema)
                    jsonschema.validate(instance=data, schema=out_schema)
                    res["e2e_check"] = "PASS"
                else:
                    res["e2e_check"] = "SKIP"
                    res["issues"].append("could not build null output dict")
            except jsonschema.ValidationError as ve:
                res["e2e_check"] = "FAIL"
                res["issues"].append(f"E2E fail: {ve.message}")
            except Exception as e:
                res["e2e_check"] = "ERROR"
                res["issues"].append(f"E2E error: {e}")
        except Exception as e:
            res["output_check"] = "ERROR"
            res["issues"].append(f"output schema error: {e}")
    else:
        res["output_model"] = str(ret) if ret else None

    return res


# ── main ─────────────────────────────────────────────────────────────────────

def main():
    setup_sys_path()
    mcp_dir = REPO / "mcp_servers"
    if not mcp_dir.exists():
        print("ERROR: no mcp_servers/ directory"); return

    servers = [d for d in sorted(mcp_dir.iterdir())
               if d.is_dir() and d.name != "__pycache__"]

    print(f"REPO: {REPO.name}")
    print(f"SERVERS: {[s.name for s in servers]}\n")

    all_results: list[dict] = []

    for srv in servers:
        print(f"── {srv.name} ──")
        tools = discover_tools_in_server(srv)
        if not tools:
            print("  (no individual tools found)\n")
            continue
        print(f"  discovered {len(tools)} tool functions\n")
        for t in tools:
            r = audit_one(t)
            all_results.append(r)
            tag = ""
            if r["issues"]:
                tag = "  ✗"
            print(f"  {r['name']:40s}  in={r['input_check']:5s}  out={r['output_check']:5s}  e2e={r['e2e_check']:5s}  gem={r['gemini_compat']:5s}{tag}")
            for iss in r["issues"]:
                print(f"      → {iss}")
        print()

    # ── summary ──────────────────────────────────────────────────────────
    total = len(all_results)
    def cnt(key, val): return sum(1 for r in all_results if r[key] == val)

    print("=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print(f"Total individual tools audited: {total}")
    print(f"  Input:  PASS={cnt('input_check','PASS')}  FAIL={cnt('input_check','FAIL')}  SKIP={cnt('input_check','SKIP')}  ERR={cnt('input_check','ERROR')}")
    print(f"  Output: PASS={cnt('output_check','PASS')}  FAIL={cnt('output_check','FAIL')}  SKIP={cnt('output_check','SKIP')}  ERR={cnt('output_check','ERROR')}")
    print(f"  E2E:    PASS={cnt('e2e_check','PASS')}  FAIL={cnt('e2e_check','FAIL')}  SKIP={cnt('e2e_check','SKIP')}  ERR={cnt('e2e_check','ERROR')}")
    print(f"  Gemini: PASS={cnt('gemini_compat','PASS')}  FAIL={cnt('gemini_compat','FAIL')}  SKIP={cnt('gemini_compat','SKIP')}  ERR={cnt('gemini_compat','ERROR')}")

    fails = [r for r in all_results
             if r["input_check"] == "FAIL" or r["output_check"] == "FAIL" or r["e2e_check"] == "FAIL"
             or r["gemini_compat"] == "FAIL"]
    if fails:
        print(f"\nOVERALL: *** FIX NEEDED *** ({len(fails)} tool(s) failing)")
        for r in fails:
            print(f"  {r['name']}:")
            for iss in r["issues"]:
                print(f"    - {iss}")
    else:
        print(f"\nOVERALL: CLEAN ✓")


if __name__ == "__main__":
    main()
