"""Filter data from a spreadsheet worksheet based on conditions."""

import os
import re
from io import BytesIO
from typing import Any

from loguru import logger
from mcp_schema import FlatBaseModel
from models.response import FilterTabResponse
from models.sheet import FilterCondition
from openpyxl import load_workbook
from openpyxl.utils import column_index_from_string, get_column_letter, range_boundaries
from openpyxl.worksheet.filters import (
    CustomFilter,
    CustomFilters,
    FilterColumn,
    Filters,
)
from pydantic import Field, TypeAdapter
from utils.decorators import make_async_background
from utils.helpers import normalize_cell_value, trim_empty_trailing_data
from utils.path_utils import PathTraversalError, resolve_under_root

# File size threshold for warning (3GB)
LARGE_FILE_WARNING_BYTES = 3 * 1024 * 1024 * 1024

# Regex pattern for column letters
_COLUMN_LETTER_PATTERN = re.compile(r"^[A-Za-z]+$")

# TypeAdapter for validating filter conditions
_filter_condition_adapter = TypeAdapter(list[FilterCondition])

# Mapping from FilterOperator enum values to openpyxl CustomFilter operators
_OPERATOR_TO_CUSTOM_FILTER: dict[str, str | None] = {
    "equals": "equal",
    "not_equals": "notEqual",
    "greater_than": "greaterThan",
    "less_than": "lessThan",
    "greater_than_or_equal": "greaterThanOrEqual",
    "less_than_or_equal": "lessThanOrEqual",
    # String operators use wildcards with 'equal' operator
    "contains": "equal",  # *value*
    "not_contains": "notEqual",  # *value*
    "starts_with": "equal",  # value*
    "ends_with": "equal",  # *value
    # These don't map to CustomFilter
    "is_empty": None,
    "is_not_empty": None,
}


def _build_filter_column(
    col_id: int, conditions: list[FilterCondition], match_all: bool
) -> FilterColumn | None:
    """Build a FilterColumn with criteria for a specific column.

    The OOXML specification limits customFilters to at most 2 customFilter children.
    This function respects that limit. When more than 2 conditions would be needed,
    only the first 2 are persisted to the file (the runtime filtering still applies
    all conditions correctly).

    Args:
        col_id: Zero-based column index within the filter range
        conditions: List of conditions for this column
        match_all: Whether to AND the conditions together

    Returns:
        FilterColumn with criteria, or None if no valid criteria
    """
    # OOXML spec: customFilters element can contain at most 2 customFilter children
    _MAX_CUSTOM_FILTERS = 2

    if not conditions:
        return None

    custom_filters: list[CustomFilter] = []
    filter_values: list[str] = []
    show_blank = False

    for cond in conditions:
        operator = cond.operator
        value = cond.value

        if operator == "is_empty":
            show_blank = True
            continue
        elif operator == "is_not_empty":
            # Can't directly express "is not empty" in Excel filters
            # Skip for now - the query still works, just won't persist this condition
            continue

        cf_operator = _OPERATOR_TO_CUSTOM_FILTER.get(operator)
        if cf_operator is None:
            continue

        # Handle string operators with wildcards
        if operator == "contains":
            val_str = f"*{value}*"
        elif operator == "not_contains":
            val_str = f"*{value}*"
        elif operator == "starts_with":
            val_str = f"{value}*"
        elif operator == "ends_with":
            val_str = f"*{value}"
        elif operator == "equals":
            # Track equals values separately - we'll decide later whether to use
            # Filters.filter (simpler) or convert to CustomFilter (when mixed)
            filter_values.append(str(value))
            continue
        else:
            val_str = str(value) if value is not None else ""

        custom_filters.append(CustomFilter(operator=cf_operator, val=val_str))

    # Build the FilterColumn
    col = FilterColumn(colId=col_id)

    # If we have simple equality filters only (no custom filters), use the Filters object
    # This is the simpler representation that Excel prefers for pure equality checks
    # Filters.filter can hold multiple values (no limit like customFilters)
    if filter_values and not custom_filters and not show_blank:
        col.filters = Filters(filter=filter_values, blank=False)
        return col

    # If we have only equality filters with show_blank, still use Filters
    if filter_values and not custom_filters and show_blank:
        col.filters = Filters(filter=filter_values, blank=True)
        return col

    # If we have custom filters (possibly mixed with equals and/or show_blank),
    # convert equals values to CustomFilter so everything is in the same format
    if custom_filters or (filter_values and custom_filters):
        # Convert any equals values to CustomFilter format
        for val in filter_values:
            custom_filters.append(CustomFilter(operator="equal", val=val))

        # OOXML spec limits customFilters to 2 children. Truncate if needed.
        # The runtime filtering still applies all conditions correctly; only
        # the persisted filter in Excel is limited.
        if len(custom_filters) > _MAX_CUSTOM_FILTERS:
            logger.warning(
                f"Column {col_id} has {len(custom_filters)} custom filter conditions, "
                f"but OOXML spec limits customFilters to {_MAX_CUSTOM_FILTERS}. "
                f"Only the first {_MAX_CUSTOM_FILTERS} will be persisted to Excel."
            )
            custom_filters = custom_filters[:_MAX_CUSTOM_FILTERS]

        cfs = CustomFilters(customFilter=custom_filters)
        if len(custom_filters) > 1:
            # openpyxl uses _and (leading underscore) since 'and' is a Python reserved word
            cfs._and = match_all
        col.customFilters = cfs

        # Note: Excel's CustomFilters doesn't directly support blank combined with
        # custom filters in the same FilterColumn. The blank would need a separate
        # Filters element, but openpyxl doesn't allow both on the same FilterColumn.
        # For now, custom filters take precedence; show_blank is best-effort.
        return col

    # If we only have blank filter
    if show_blank:
        col.filters = Filters(blank=True)
        return col

    return None


def _is_column_letter(value: str) -> bool:
    """Check if a string is a valid Excel column letter (A, B, AA, etc.)."""
    return bool(_COLUMN_LETTER_PATTERN.match(value))


def _resolve_column_index(
    column: str,
    headers: list[str] | None,
    use_headers: bool,
    num_cols: int,
    range_start_col: int = 1,
) -> tuple[int | None, str | None]:
    """Resolve a column reference to a 0-based column index within the data range.

    Args:
        column: Column letter (A, B) or header name
        headers: List of header values (if use_headers is True)
        use_headers: Whether to allow header name lookups
        num_cols: Number of columns in the data (for error messages)
        range_start_col: 1-based column index of the first column in the range
                         (e.g., 3 for a range starting at column C)

    Returns:
        Tuple of (0-based column index within the data range or None, error message or None)
    """
    # When use_headers is enabled, try header name lookup FIRST
    # This prevents short header names like "ID", "Qty", "Amt" from being
    # misinterpreted as Excel column letters (ID=238, etc.)
    if use_headers and headers:
        # Case-insensitive header matching
        column_lower = column.lower()
        for idx, header in enumerate(headers):
            if header is not None and str(header).lower() == column_lower:
                return idx, None

    # Fall back to column letter interpretation
    if _is_column_letter(column):
        try:
            # Convert column letter to 1-based sheet-wide index
            sheet_col_1based = column_index_from_string(column.upper())
            # Convert to 0-based index relative to the range
            col_idx = sheet_col_1based - range_start_col
            # Validate the column is within the range
            if 0 <= col_idx < num_cols:
                return col_idx, None
            else:
                # Build available columns message using actual sheet column letters
                available_cols = ", ".join(
                    get_column_letter(range_start_col + i)
                    for i in range(min(num_cols, 10))
                )
                if num_cols > 10:
                    available_cols += f"... ({num_cols} columns total)"
                return (
                    None,
                    f"Column '{column}' is out of range. Available columns: {available_cols}",
                )
        except ValueError:
            pass

    # Column not found - provide helpful error
    if use_headers and headers:
        # Show available headers
        available_headers = ", ".join(f"'{h}'" for h in headers[:10] if h)
        if len(headers) > 10:
            available_headers += f"... ({len(headers)} headers total)"
        # Use actual sheet column letters for the range
        available_cols = ", ".join(
            get_column_letter(range_start_col + i) for i in range(min(num_cols, 10))
        )
        return None, (
            f"Column '{column}' not found. "
            f"Available headers: {available_headers}. "
            f"Or use column letters: {available_cols}"
        )
    else:
        # Use actual sheet column letters for the range
        available_cols = ", ".join(
            get_column_letter(range_start_col + i) for i in range(min(num_cols, 10))
        )
        if num_cols > 10:
            available_cols += f"... ({num_cols} columns total)"
        return None, f"Column '{column}' not found. Available columns: {available_cols}"


def _evaluate_condition(cell_value: Any, operator: str, filter_value: Any) -> bool:
    """Evaluate a single filter condition against a cell value.

    Args:
        cell_value: The value from the cell
        operator: The filter operator
        filter_value: The value to compare against

    Returns:
        True if the condition is satisfied, False otherwise
    """
    # Handle is_empty and is_not_empty first
    if operator == "is_empty":
        return cell_value is None or cell_value == ""
    if operator == "is_not_empty":
        return cell_value is not None and cell_value != ""

    # For other operators, we need a filter_value
    if filter_value is None:
        return False

    # String operations
    if operator == "contains":
        if cell_value is None:
            return False
        return str(filter_value).lower() in str(cell_value).lower()

    if operator == "not_contains":
        if cell_value is None:
            return True
        return str(filter_value).lower() not in str(cell_value).lower()

    if operator == "starts_with":
        if cell_value is None:
            return False
        return str(cell_value).lower().startswith(str(filter_value).lower())

    if operator == "ends_with":
        if cell_value is None:
            return False
        return str(cell_value).lower().endswith(str(filter_value).lower())

    # Equality operations
    if operator == "equals":
        if cell_value is None and filter_value is None:
            return True
        if cell_value is None or filter_value is None:
            return False
        # Try numeric comparison first
        try:
            return float(cell_value) == float(filter_value)
        except (ValueError, TypeError):
            pass
        # Fall back to string comparison (case-insensitive)
        return str(cell_value).lower() == str(filter_value).lower()

    if operator == "not_equals":
        if cell_value is None and filter_value is None:
            return False
        if cell_value is None or filter_value is None:
            return True
        # Try numeric comparison first
        try:
            return float(cell_value) != float(filter_value)
        except (ValueError, TypeError):
            pass
        # Fall back to string comparison (case-insensitive)
        return str(cell_value).lower() != str(filter_value).lower()

    # Numeric comparisons
    if operator in (
        "greater_than",
        "less_than",
        "greater_than_or_equal",
        "less_than_or_equal",
    ):
        if cell_value is None:
            return False
        try:
            cell_num = float(cell_value)
            filter_num = float(filter_value)
        except (ValueError, TypeError):
            return False

        if operator == "greater_than":
            return cell_num > filter_num
        if operator == "less_than":
            return cell_num < filter_num
        if operator == "greater_than_or_equal":
            return cell_num >= filter_num
        if operator == "less_than_or_equal":
            return cell_num <= filter_num

    return False


def _apply_filters(
    row: list[Any],
    conditions: list[FilterCondition],
    column_indices: dict[str, int],
    match_all: bool,
) -> bool:
    """Apply filter conditions to a row using pre-computed column indices.

    Args:
        row: The data row to filter
        conditions: List of filter conditions
        column_indices: Pre-computed mapping of column names to 0-based indices
        match_all: If True, all conditions must match (AND); if False, any match (OR)

    Returns:
        True if the row passes the filter, False otherwise
    """
    if not conditions:
        return True

    results = []
    for condition in conditions:
        col_idx = column_indices.get(condition.column)
        if col_idx is None:
            # Column not found - condition fails (should not happen after validation)
            results.append(False)
            continue

        cell_value = row[col_idx] if col_idx < len(row) else None
        result = _evaluate_condition(cell_value, condition.operator, condition.value)
        results.append(result)

    if match_all:
        return all(results)
    else:
        return any(results)


class FilterTabInput(FlatBaseModel):
    file_path: str = Field(
        ...,
        description="Absolute path to the .xlsx file starting with '/' (e.g., '/data/report.xlsx')",
    )
    tab_index: int = Field(
        ...,
        description="0-based worksheet tab index (e.g., 0 for first tab)",
        ge=0,
    )
    filters: list[dict[str, Any]] = Field(
        ...,
        description=(
            "List of filter condition objects. Each condition has: "
            "'column' (column letter like 'A' or header name if use_headers=true), "
            "'operator' (see valid operators below), "
            "'value' (comparison value, optional for is_empty/is_not_empty). "
            "Valid operators: 'equals', 'not_equals', 'greater_than', 'less_than', "
            "'greater_than_or_equal', 'less_than_or_equal', 'contains', 'not_contains', "
            "'starts_with', 'ends_with', 'is_empty', 'is_not_empty'"
        ),
    )
    cell_range: str | None = Field(
        None,
        description="Optional cell range to filter within (e.g., 'A1:D100', 'B5:F50'). If null, filters entire worksheet. Must be a range (A1:B10), not a single cell",
    )
    match_all: bool = Field(
        True,
        description="If true (default), all filter conditions must match for a row to be included (AND logic). If false, any matching condition includes the row (OR logic)",
    )
    use_headers: bool = Field(
        True,
        description="If true (default), first row is treated as column headers, excluded from filtered results, and column names in filter conditions can reference header values (case-insensitive)",
    )
    include_diagnostics: bool = Field(
        False,
        description="If True, include diagnostic info when no matches found (default False for efficiency)",
    )
    compact: bool = Field(
        False,
        description="Use compact CSV-style output without formatting (default False)",
    )


@make_async_background
def filter_tab(input: FilterTabInput) -> str:
    """Filter worksheet data based on column conditions and return matching rows."""
    file_path = input.file_path
    tab_index = input.tab_index
    filters = input.filters
    cell_range = input.cell_range
    match_all = input.match_all
    use_headers = input.use_headers
    include_diagnostics = input.include_diagnostics
    compact = input.compact

    # Validate file_path
    if not isinstance(file_path, str) or not file_path:
        return "File path is required"
    if not file_path.startswith("/"):
        return "File path must start with /"
    if not file_path.lower().endswith(".xlsx"):
        return "File path must end with .xlsx"

    # Validate tab_index
    if not isinstance(tab_index, int) or tab_index < 0:
        return "Tab index must be a non-negative integer"

    # Validate and parse filters
    if not isinstance(filters, list):
        return "Filters must be a list"
    if not filters:
        return "At least one filter condition is required"

    try:
        conditions = _filter_condition_adapter.validate_python(filters)
    except Exception as exc:
        return f"Invalid filter conditions: {repr(exc)}"

    # Resolve path
    try:
        target_path = resolve_under_root(file_path)
    except PathTraversalError:
        return f"Invalid path: {file_path}"

    # Check file exists
    try:
        if not os.path.exists(target_path):
            return f"File not found: {file_path}"
        if not os.path.isfile(target_path):
            return f"Not a file: {file_path}"

        file_size = os.path.getsize(target_path)
        if file_size > LARGE_FILE_WARNING_BYTES:
            size_gb = file_size / (1024 * 1024 * 1024)
            logger.warning(
                f"Processing large file: {file_path} ({size_gb:.2f}GB). "
                "This may take longer and use significant memory."
            )
    except Exception as exc:
        return f"Failed to access file: {repr(exc)}"

    # Read file bytes
    try:
        with open(target_path, "rb") as f:
            file_bytes = f.read()
    except Exception as exc:
        return f"Failed to read file: {repr(exc)}"

    # Load workbook (read-only for data extraction)
    try:
        workbook = load_workbook(BytesIO(file_bytes), read_only=True, data_only=True)
    except Exception as exc:
        return f"Failed to load workbook: {repr(exc)}"

    try:
        # Validate tab index
        if tab_index >= len(workbook.sheetnames):
            sheet_count = len(workbook.sheetnames)
            workbook.close()
            return f"Tab index {tab_index} is out of range. Available sheets: {sheet_count}"

        sheet_name = workbook.sheetnames[tab_index]
        worksheet = workbook[sheet_name]

        # Read data based on cell_range
        all_rows: list[list[Any]] = []
        range_str = "all"
        # 1-based column index of the first column in the filter range
        # (used to convert sheet column letters to range-relative indices)
        range_start_col = 1

        if cell_range is not None:
            cell_range = cell_range.strip().upper()
            range_str = cell_range

            if ":" not in cell_range:
                workbook.close()
                return "Cell range must be a range like 'A1:D100', not a single cell"

            try:
                # Parse the range to get the starting column (1-based)
                min_col, _min_row, _max_col, _max_row = range_boundaries(cell_range)
                if min_col is not None:
                    range_start_col = min_col

                cell_obj = worksheet[cell_range]
                if not isinstance(cell_obj, tuple):
                    cell_obj = (cell_obj,)

                for row in cell_obj:
                    if isinstance(row, tuple):
                        all_rows.append(
                            [
                                normalize_cell_value(cell.value, cell.number_format)
                                for cell in row
                            ]
                        )
                    else:
                        all_rows.append(
                            [normalize_cell_value(row.value, row.number_format)]
                        )
            except Exception as exc:
                workbook.close()
                return f"Invalid cell range '{cell_range}': {repr(exc)}"
        else:
            # Read entire sheet â€” use cell objects for number_format access
            for row in worksheet.iter_rows():
                all_rows.append(
                    [
                        normalize_cell_value(cell.value, cell.number_format)
                        for cell in row
                    ]
                )

        workbook.close()

        # Trim empty trailing data
        all_rows = trim_empty_trailing_data(all_rows)

        if not all_rows:
            return str(
                FilterTabResponse(
                    range=range_str,
                    filters_applied=len(conditions),
                    rows_matched=0,
                    total_rows=0,
                    values=[],
                    headers=None,
                    compact=compact,
                )
            )

        # Extract headers if use_headers is True
        headers: list[str] | None = None
        data_rows = all_rows

        if use_headers and all_rows:
            headers = [str(v) if v is not None else "" for v in all_rows[0]]
            data_rows = all_rows[1:]

        # Determine number of columns for validation
        num_cols = max(len(row) for row in all_rows) if all_rows else 0

        # First, validate all column references before filtering
        column_errors: list[str] = []
        column_indices: dict[str, int] = {}
        for condition in conditions:
            if condition.column not in column_indices:
                col_idx, error = _resolve_column_index(
                    condition.column, headers, use_headers, num_cols, range_start_col
                )
                if col_idx is not None:
                    column_indices[condition.column] = col_idx
                elif error and error not in column_errors:
                    column_errors.append(error)

        # If there are column resolution errors, return them immediately
        if column_errors:
            error_msg = "Filter error: " + "; ".join(column_errors)
            return error_msg

        # Apply filters to each row
        matched_rows: list[list[Any]] = []
        for row in data_rows:
            if _apply_filters(row, conditions, column_indices, match_all):
                matched_rows.append(row)

        # Set auto_filter on the underlying file so the filter persists in Excel.
        # This includes both the range AND the filter criteria.
        # This is done AFTER validation and filtering succeed to avoid mutating
        # the source file when the operation would ultimately fail.
        if cell_range is not None or all_rows:
            try:
                wb_write = load_workbook(BytesIO(file_bytes))
                ws_write = wb_write[sheet_name]

                # Set the auto_filter range
                if cell_range is not None:
                    ws_write.auto_filter.ref = cell_range
                else:
                    af_num_cols = max(len(row) for row in all_rows)
                    af_num_rows = len(all_rows)
                    last_col = get_column_letter(af_num_cols)
                    ws_write.auto_filter.ref = f"A1:{last_col}{af_num_rows}"

                # Group conditions by column index
                conditions_by_col: dict[int, list[FilterCondition]] = {}
                for cond in conditions:
                    col_idx = column_indices.get(cond.column)
                    if col_idx is not None:
                        if col_idx not in conditions_by_col:
                            conditions_by_col[col_idx] = []
                        conditions_by_col[col_idx].append(cond)

                # Clear existing filter columns and add new ones
                ws_write.auto_filter.filterColumn = []

                # Add filter criteria for each column
                for col_idx, col_conditions in conditions_by_col.items():
                    filter_col = _build_filter_column(
                        col_id=col_idx,
                        conditions=col_conditions,
                        match_all=match_all,
                    )
                    if filter_col is not None:
                        ws_write.auto_filter.filterColumn.append(filter_col)

                wb_write.save(target_path)
                wb_write.close()
            except Exception as exc:
                logger.warning(f"Failed to set auto_filter on file: {repr(exc)}")

        # Build diagnostic info if no matches found and diagnostics requested
        diagnostic: str | None = None
        if include_diagnostics and len(matched_rows) == 0 and data_rows:
            # Collect sample values from filtered columns to help debug
            diag_parts = []
            for condition in conditions:
                col_idx = column_indices.get(condition.column)
                if col_idx is not None:
                    # Get sample values from this column (first 5 non-empty)
                    sample_values = []
                    for row in data_rows[:10]:
                        if col_idx < len(row) and row[col_idx] is not None:
                            val = row[col_idx]
                            val_type = type(val).__name__
                            sample_values.append(f"{repr(val)} ({val_type})")
                            if len(sample_values) >= 5:
                                break
                    if sample_values:
                        col_name = condition.column
                        if headers and col_idx < len(headers):
                            col_name = f"{headers[col_idx]} (column {get_column_letter(col_idx + 1)})"
                        diag_parts.append(
                            f"Column '{col_name}' sample values: {', '.join(sample_values)}"
                        )
                    else:
                        diag_parts.append(
                            f"Column '{condition.column}' has no values in first 10 rows"
                        )
            if diag_parts:
                diagnostic = (
                    "No rows matched. Debug info:\n"
                    + "\n".join(f"  - {p}" for p in diag_parts)
                    + f"\nFilter attempted: {', '.join(f'{c.column} {c.operator} {repr(c.value)}' for c in conditions)}"
                )

        response = FilterTabResponse(
            range=range_str,
            filters_applied=len(conditions),
            rows_matched=len(matched_rows),
            total_rows=len(data_rows),
            values=matched_rows,
            headers=headers,
            diagnostic=diagnostic,
            compact=compact,
        )
        return str(response)

    except Exception as exc:
        try:
            workbook.close()
        except Exception:
            pass
        return f"Unexpected error: {repr(exc)}"
