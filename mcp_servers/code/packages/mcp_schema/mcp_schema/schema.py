"""Flatten JSON schemas for LLM Function Calling compatibility."""

from copy import deepcopy
from typing import Any

from pydantic import BaseModel, ConfigDict

UNSUPPORTED_FIELDS = frozenset(
    [
        "$defs",
        "$ref",
        "default",
        "title",
        "additionalProperties",
        "const",
        "minimum",
        "maximum",
        "exclusiveMinimum",
        "exclusiveMaximum",
        "minItems",
        "maxItems",
        "minLength",
        "maxLength",
        "pattern",
        "uniqueItems",
        "examples",
        "prefixItems",
    ]
)


def flatten_schema(schema: dict[str, Any]) -> dict[str, Any]:
    """Flatten a JSON schema by inlining $ref and removing unsupported fields."""

    def get_type_name(t: dict[str, Any]) -> str:
        if "type" in t:
            return str(t["type"])
        ref_val = t.get("$ref")
        if isinstance(ref_val, str) and "/" in ref_val:
            return ref_val.split("/")[-1]
        return "unknown"

    def inline_refs(
        obj: Any,
        defs: dict[str, Any] | None = None,
        seen: set[str] | None = None,
    ) -> Any:
        if seen is None:
            seen = set()

        if isinstance(obj, dict):
            if "$defs" in obj:
                local_defs = {**(defs or {}), **obj["$defs"]}
            else:
                local_defs = defs

            ref = obj.get("$ref")
            if isinstance(ref, str) and ref.startswith("#/$defs/") and local_defs:
                ref_key = ref.split("/")[-1]
                if ref_key in local_defs:
                    sibling_props = {
                        k: inline_refs(v, local_defs, seen)
                        for k, v in obj.items()
                        if k not in UNSUPPORTED_FIELDS and k not in ("$ref", "anyOf")
                    }
                    if ref_key in seen:
                        return {
                            "type": "object",
                            "description": f"(recursive: {ref_key})",
                            **sibling_props,
                        }
                    inlined_def = inline_refs(
                        deepcopy(local_defs[ref_key]), local_defs, seen | {ref_key}
                    )
                    return {**inlined_def, **sibling_props}

            for union_key in ("anyOf", "oneOf", "allOf"):
                branches = obj.get(union_key)
                if not isinstance(branches, list) or len(branches) == 0:
                    continue
                non_null_types = [
                    item
                    for item in branches
                    if isinstance(item, dict) and item.get("type") != "null"
                ]

                if len(non_null_types) == 0:
                    result = {
                        k: inline_refs(v, local_defs, seen)
                        for k, v in obj.items()
                        if k not in UNSUPPORTED_FIELDS and k not in ("anyOf", "oneOf", "allOf")
                    }
                    if "type" not in result:
                        result["type"] = "string"
                    return result

                field_description = obj.get("description")
                result = {
                    k: inline_refs(v, local_defs, seen)
                    for k, v in obj.items()
                    if k not in UNSUPPORTED_FIELDS and k not in ("anyOf", "oneOf", "allOf")
                }

                if union_key == "allOf":
                    for branch in non_null_types:
                        inlined = inline_refs(branch, local_defs, seen)
                        if not isinstance(inlined, dict):
                            continue
                        branch_props = inlined.pop("properties", None)
                        branch_required = inlined.pop("required", None)
                        result.update(inlined)
                        if branch_props:
                            result.setdefault("properties", {}).update(branch_props)
                        if branch_required:
                            existing = set(result.get("required", []))
                            result["required"] = sorted(existing | set(branch_required))
                    if field_description is not None:
                        result["description"] = field_description
                else:
                    item = non_null_types[0]
                    result.update(inline_refs(item, local_defs, seen))

                    if len(non_null_types) > 1:
                        type_names = [get_type_name(t) for t in non_null_types]
                        union_note = f"(Union of: {', '.join(type_names)})"
                        if field_description:
                            result["description"] = f"{field_description} {union_note}"
                        else:
                            result["description"] = union_note
                    elif field_description is not None:
                        result["description"] = field_description

                return result

            # Capture prefixItems before filtering (for tuple types)
            prefix_items = obj.get("prefixItems")

            inlined: dict[str, Any] = {}
            for key, value in obj.items():
                if key in UNSUPPORTED_FIELDS:
                    continue
                if key == "properties" and isinstance(value, dict):
                    # Don't filter property names - only recurse into their schemas
                    inlined[key] = {
                        prop_name: inline_refs(prop_schema, local_defs, seen)
                        for prop_name, prop_schema in value.items()
                    }
                else:
                    inlined[key] = inline_refs(value, local_defs, seen)

            # Ensure arrays have items (required by Gemini)
            if inlined.get("type") == "array" and "items" not in inlined:
                # Try to infer type from prefixItems (tuple types)
                if isinstance(prefix_items, list) and len(prefix_items) > 0:
                    # Use inline_refs to properly flatten nested structures
                    inlined["items"] = inline_refs(prefix_items[0], local_defs, seen)
                else:
                    inlined["items"] = {"type": "string"}

            return inlined

        if isinstance(obj, list):
            return [inline_refs(item, defs, seen) for item in obj]

        return obj

    flattened = inline_refs(schema)
    _annotate_optional_fields(flattened)
    return flattened


def _annotate_optional_fields(schema: dict[str, Any]) -> None:
    """Mark non-required properties with ``nullable: true`` and an (Optional) prefix.

    After flattening strips ``anyOf`` and ``default``, the only signal that a
    field is optional is its absence from the ``required`` array.  LLMs
    frequently overlook this, so we add two redundant hints:

    1. ``"nullable": true`` — a structured flag Gemini understands.
    2. ``"(Optional) "`` prefix in the description — a natural-language fallback.
    """
    required = set(schema.get("required", []))
    for name, prop in schema.get("properties", {}).items():
        if not isinstance(prop, dict):
            continue
        if name not in required:
            prop["nullable"] = True
            desc = prop.get("description", "")
            if not desc.startswith("(Optional)"):
                prop["description"] = f"(Optional) {desc}" if desc else "(Optional)"
        if prop.get("type") == "object" and "properties" in prop:
            _annotate_optional_fields(prop)
        elif prop.get("type") == "array" and isinstance(prop.get("items"), dict):
            items = prop["items"]
            if items.get("type") == "object" and "properties" in items:
                _annotate_optional_fields(items)


def _flatten_schema_inplace(schema: dict[str, Any], _cls: type | None = None) -> None:
    """``json_schema_extra`` callback that flattens *in-place*.

    Pydantic's ``json_schema_extra`` callable receives ``(schema, cls)`` and
    must **mutate** the schema dict — its return value is ignored.  We delegate
    to ``flatten_schema`` (which returns a new dict) and then swap the contents
    of the original dict so callers see the flattened version.
    """
    flattened = flatten_schema(schema)
    schema.clear()
    schema.update(flattened)


class FlatBaseModel(BaseModel):
    """BaseModel subclass that generates flattened JSON schemas.

    Use this instead of BaseModel for models that need LLM-compatible schemas.
    """

    model_config = ConfigDict(json_schema_extra=_flatten_schema_inplace)

    @classmethod
    def model_json_schema(cls, **kwargs: Any) -> dict[str, Any]:
        """Generate a flattened JSON schema.

        Flattening is handled by the ``json_schema_extra`` callback
        (``_flatten_schema_inplace``) which runs inside
        ``super().model_json_schema()``, so no extra wrapping is needed.
        """
        return super().model_json_schema(**kwargs)


OutputBaseModel = BaseModel
