import base64
import io
import os
import re

from docx import Document
from mcp_schema import FlatBaseModel
from PIL import Image
from pydantic import Field
from utils.decorators import make_async_background
from utils.image_cache import (
    IMAGE_CACHE,
    IMAGE_QUALITY,
    MAX_IMAGE_HEIGHT,
    MAX_IMAGE_WIDTH,
)
from utils.models import (
    Cell,
    DocumentBody,
    ImageRun,
    Paragraph,
    ReadDocumentContentMetadata,
    ReadDocumentContentResponse,
    Run,
    Table,
    TableRow,
)
from utils.pagination import PARAGRAPHS_PER_PAGE, calculate_total_pages
from utils.path_utils import resolve_under_root


def _sanitize_filename(name: str) -> str:
    """Sanitize a filename to be filesystem-safe."""
    # Remove path separators and other problematic characters
    name = re.sub(r'[<>:"/\\|?*]', "_", name)
    # Remove leading/trailing spaces and dots
    name = name.strip(". ")
    return name if name else "unnamed"


def _compress_image_to_base64(image_bytes: bytes) -> str:
    """Compress and convert image to base64 using same technique as read_image tool.

    Args:
        image_bytes: Raw image bytes from docx

    Returns:
        Base64 encoded string of compressed JPEG image
    """
    buffer = io.BytesIO(image_bytes)

    with Image.open(buffer) as img:
        # Convert to RGB (handle RGBA, P, LA modes)
        if img.mode in ("RGBA", "P", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            if img.mode == "P":
                img = img.convert("RGBA")
            if img.mode in ("RGBA", "LA"):
                background.paste(img, mask=img.split()[-1])
                img = background
            else:
                img = img.convert("RGB")
        elif img.mode != "RGB":
            img = img.convert("RGB")

        if img.width > MAX_IMAGE_WIDTH or img.height > MAX_IMAGE_HEIGHT:
            img.thumbnail((MAX_IMAGE_WIDTH, MAX_IMAGE_HEIGHT), Image.Resampling.LANCZOS)

        output_buffer = io.BytesIO()
        img.save(output_buffer, format="JPEG", quality=IMAGE_QUALITY, optimize=True)
        compressed_bytes = output_buffer.getvalue()

    return base64.b64encode(compressed_bytes).decode("utf-8")


def _extract_image_from_run(
    run, file_path: str, paragraph_id: str, run_idx: int
) -> ImageRun | None:
    """Extract image from a run and store in memory cache.

    Images are compressed once and stored as base64 in memory dictionary.
    They can be retrieved using the read_image tool with file_path and annotation.

    Args:
        run: The docx run object
        file_path: Full file path of the document (used as cache key prefix)
        paragraph_id: Paragraph identifier for unique naming
        run_idx: Run index

    Returns:
        ImageRun object if image was found and extracted, None otherwise
    """
    try:
        inline_shapes = run._element.xpath(".//pic:pic")
        if not inline_shapes:
            return None

        inline = run._element.xpath(".//a:blip/@r:embed")
        if not inline:
            return None

        image_rId = inline[0]
        image_part = run.part.related_parts.get(image_rId)
        if not image_part:
            return None

        image_bytes = image_part.blob

        base64_data = _compress_image_to_base64(image_bytes)

        safe_para_id = paragraph_id.replace(".", "_")
        annotation_key = f"{safe_para_id}_r{run_idx}"

        cache_key = f"{file_path}::{annotation_key}"
        IMAGE_CACHE.set(cache_key, base64_data)

        # Try to get dimensions
        width = None
        height = None
        try:
            extent_elements = run._element.xpath(".//wp:extent")
            if extent_elements:
                extent = extent_elements[0]
                width = int(extent.get("cx", 0))
                height = int(extent.get("cy", 0))
        except Exception:
            pass

        # Try to get alt text
        alt_text = None
        try:
            desc_elements = run._element.xpath(".//pic:cNvPr/@descr")
            if desc_elements:
                alt_text = desc_elements[0]
        except Exception:
            pass

        run_id = f"{paragraph_id}.r.{run_idx}"
        return ImageRun(
            id=run_id,
            type="image",
            annotation=annotation_key,
            width=width,
            height=height,
            alt_text=alt_text if alt_text else None,
        )
    except Exception:
        return None


def _serialize_run(
    paragraph_id: str, run, r_idx: int, file_path: str
) -> Run | ImageRun:
    """Serialize a run with its formatting, detecting images."""
    image_run = _extract_image_from_run(run, file_path, paragraph_id, r_idx)
    if image_run:
        return image_run

    run_id = f"{paragraph_id}.r.{r_idx}"
    font = run.font
    style_obj = getattr(run, "style", None)
    style_name = style_obj.name if style_obj else None

    bold = bool(getattr(run, "bold", False) or getattr(font, "bold", False)) or None
    italic = (
        bool(getattr(run, "italic", False) or getattr(font, "italic", False)) or None
    )
    underline = (
        bool(getattr(run, "underline", False) or getattr(font, "underline", False))
        or None
    )
    strikethrough = bool(getattr(font, "strike", False)) or None

    return Run(
        id=run_id,
        text=run.text,
        bold=bold if bold else None,
        italic=italic if italic else None,
        underline=underline if underline else None,
        strikethrough=strikethrough if strikethrough else None,
        style=style_name,
    )


def _serialize_paragraph(
    prefix: str, paragraph, p_idx: int, file_path: str
) -> Paragraph:
    """Serialize a paragraph with its runs."""
    paragraph_id = f"{prefix}.p.{p_idx}"
    runs = [
        _serialize_run(paragraph_id, r, i, file_path)
        for i, r in enumerate(paragraph.runs)
    ]
    alignment = (
        paragraph.alignment.name if getattr(paragraph, "alignment", None) else None
    )
    style_name = paragraph.style.name if getattr(paragraph, "style", None) else None
    return Paragraph(
        id=paragraph_id,
        style=style_name,
        alignment=alignment,
        runs=runs,
    )


def _serialize_table(prefix: str, table, t_idx: int, file_path: str) -> Table:
    """Serialize a table with its rows and cells."""
    table_id = f"{prefix}.tbl.{t_idx}"
    rows_out: list[TableRow] = []
    for r_idx, row in enumerate(table.rows):
        cells_out: list[Cell] = []
        for c_idx, cell in enumerate(row.cells):
            cell_prefix = f"{table_id}.r.{r_idx}.c.{c_idx}"
            cell_paragraphs = [
                _serialize_paragraph(cell_prefix, p, i, file_path)
                for i, p in enumerate(cell.paragraphs)
            ]
            cells_out.append(Cell(id=f"{cell_prefix}", paragraphs=cell_paragraphs))
        rows_out.append(TableRow(cells=cells_out))
    return Table(id=table_id, rows=rows_out)


class ReadDocumentContentInput(FlatBaseModel):
    file_path: str = Field(
        ...,
        description="Absolute path to the .docx file starting with '/' (e.g., '/documents/report.docx')",
    )
    page_index: int | None = Field(
        None,
        description=(
            "Optional 0-based page index for reading large documents in chunks. "
            "page_index=0 returns paragraphs 0-49, page_index=1 returns paragraphs 50-99, etc. "
            "Omit to read the entire document at once. "
            "The response metadata includes 'total_pages' showing valid range (0 to total_pages-1)."
        ),
    )


@make_async_background
def read_document_content(input: ReadDocumentContentInput) -> str:
    """Read and parse a .docx document into structured JSON with stable element identifiers.

    Returns paragraphs and tables with IDs like 'body.p.0', 'body.tbl.0.r.0.c.0' for targeted editing.
    For large documents, use page_index to read in chunks of ~50 paragraphs each.
    """
    file_path = input.file_path
    page_index = input.page_index

    if not isinstance(file_path, str) or not file_path:
        return "File path is required"
    if not file_path.startswith("/"):
        return "File path must start with /"
    if not file_path.lower().endswith(".docx"):
        return "File path must end with .docx"

    target_path = resolve_under_root(file_path)

    try:
        if not os.path.exists(target_path):
            return f"File not found: {file_path}"
        if not os.path.isfile(target_path):
            return f"Not a file: {file_path}"

        doc = Document(target_path)
    except Exception as exc:
        return f"Failed to read document: {repr(exc)}"

    # Determine paragraph range based on page_index
    all_paragraphs = list(doc.paragraphs)
    total_paragraphs = len(all_paragraphs)
    total_pages = calculate_total_pages(total_paragraphs)

    start_idx = 0
    end_idx = total_paragraphs
    page_range_str = None

    if page_index is not None:
        if page_index < 0 or page_index >= total_pages:
            return f"Invalid page_index: {page_index}. Document has {total_pages} pages (0 to {total_pages - 1})."

        start_idx = page_index * PARAGRAPHS_PER_PAGE
        end_idx = min(start_idx + PARAGRAPHS_PER_PAGE, total_paragraphs)
        if end_idx > start_idx:
            page_range_str = f"paragraphs {start_idx} to {end_idx - 1}"
        else:
            page_range_str = "empty page"

    # Extract paragraphs in range
    body_prefix = "body"
    selected_paragraphs = all_paragraphs[start_idx:end_idx]
    body_paragraphs = [
        _serialize_paragraph(body_prefix, p, i, file_path)
        for i, p in enumerate(selected_paragraphs, start=start_idx)
    ]

    # Tables: For simplicity, include all tables when paginating
    # (determining table location within sections is complex)
    body_tables = [
        _serialize_table(body_prefix, t, i, file_path) for i, t in enumerate(doc.tables)
    ]

    # Calculate total runs and images
    total_runs = 0
    num_images = 0
    for para in body_paragraphs:
        total_runs += len(para.runs)
        for run in para.runs:
            if isinstance(run, ImageRun):
                num_images += 1
    for tbl in body_tables:
        for row in tbl.rows:
            for cell in row.cells:
                for para in cell.paragraphs:
                    total_runs += len(para.runs)
                    for run in para.runs:
                        if isinstance(run, ImageRun):
                            num_images += 1

    _, ext = os.path.splitext(file_path)
    extension = ext[1:].lower() if ext.startswith(".") else ext.lower()

    result = ReadDocumentContentResponse(
        filepath=file_path,
        extension=extension,
        status="success",
        metadata=ReadDocumentContentMetadata(
            num_paragraphs=len(body_paragraphs),
            num_tables=len(body_tables),
            num_sections=len(doc.sections),
            total_runs=total_runs,
            num_images=num_images,
            total_pages=total_pages,
            page_index=page_index,
            page_range=page_range_str,
        ),
        body=DocumentBody(paragraphs=body_paragraphs, tables=body_tables),
    )

    return str(result)
