import os
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Annotated

import fitz  # PyMuPDF - much faster than pypdf for text extraction
from mcp_schema import OutputBaseModel
from pydantic import ConfigDict, Field
from utils.decorators import make_async_background
from utils.ocr import ocr_available, ocr_page_image

PDF_ROOT = os.getenv("APP_PDF_ROOT") or os.getenv("APP_FS_ROOT", "/filesystem")

# Parallelization settings
MAX_WORKERS = 4  # Number of worker threads for parallel page processing
PARALLEL_THRESHOLD = 5  # Only parallelize if more than this many pages


def _resolve_under_root(path: str) -> tuple[str, str | None]:
    """Map path to the PDF root with security checks.

    Returns:
        Tuple of (resolved_path, error_message). If error_message is not None,
        the path is invalid and should not be used.
    """
    path = path.lstrip("/")
    full_path = os.path.join(PDF_ROOT, path)

    # Normalize the path
    normalized_path = os.path.normpath(full_path)

    # Security check: ensure the normalized path is still under PDF_ROOT
    normalized_root = os.path.normpath(PDF_ROOT)
    if (
        not normalized_path.startswith(normalized_root + os.sep)
        and normalized_path != normalized_root
    ):
        return "", "Path traversal detected: path cannot escape PDF root"

    return normalized_path, None


class SearchMatch(OutputBaseModel):
    """A single search match result."""

    model_config = ConfigDict(extra="forbid")

    page: int = Field(
        ...,
        description="1-indexed page number where this match was found (e.g., 1 for first page).",
    )
    line: int = Field(
        ...,
        description="1-indexed line number within the page where match was found. Lines are determined by newline characters in extracted text, which may differ from visual lines in the PDF.",
    )
    char_start: int = Field(
        ...,
        description="0-indexed character position where the match starts within the line. First character of line is position 0.",
    )
    char_end: int = Field(
        ...,
        description="0-indexed character position where the match ends (exclusive, like Python slice). Match text is line[char_start:char_end].",
    )
    context: str = Field(
        ...,
        description="Text surrounding the match, with the match included. Truncated to context_chars on each side. Prefixed with '...' if truncated at start, suffixed with '...' if truncated at end.",
    )

    def __str__(self) -> str:
        return f"[Page {self.page}, Line {self.line}, Chars {self.char_start}-{self.char_end}]: {self.context}"


class SearchResult(OutputBaseModel):
    """Search results for PDF text search."""

    model_config = ConfigDict(extra="forbid")

    query: str = Field(
        ...,
        description="The original search query string that was used for this search.",
    )
    total_matches: int = Field(
        ...,
        description="Total number of matches found and returned. May equal max_results if search was truncated. Does not represent total matches in document if limit was reached.",
    )
    matches: list[SearchMatch] = Field(
        default_factory=list,
        description="List of SearchMatch objects, each containing location and context for one match. Ordered by page number, then line number, then character position. Empty list if no matches found.",
    )
    error: str | None = Field(
        None,
        description="Error message string if search failed (e.g., file not found, invalid path). None if search completed successfully (even with zero matches).",
    )

    def __str__(self) -> str:
        if self.error:
            return f"Search failed: {self.error}"

        if self.total_matches == 0:
            return f'No matches found for "{self.query}"'

        lines = [f'Found {self.total_matches} match(es) for "{self.query}":', ""]

        for idx, match in enumerate(self.matches, 1):
            lines.append(f"{idx}. {match}")

        return "\n".join(lines)


def _search_in_text(
    text: str,
    query: str,
    page_num: int,
    case_sensitive: bool,
    whole_word: bool,
    context_chars: int,
) -> list[SearchMatch]:
    """Search for query in text and return matches with positions.

    Args:
        text: Text to search in
        query: Search query
        page_num: Page number for results
        case_sensitive: Whether to match case
        whole_word: Whether to match whole words only
        context_chars: Number of characters to show around match

    Returns:
        List of SearchMatch objects
    """
    matches = []
    lines = text.split("\n")

    # Precompute absolute character offset for each line in the full text
    line_offsets: list[int] = []
    offset = 0
    for line in lines:
        line_offsets.append(offset)
        offset += len(line) + 1  # +1 for the \n

    for line_idx, line in enumerate(lines):
        search_text = line if case_sensitive else line.lower()
        search_query = query if case_sensitive else query.lower()

        if whole_word:
            pattern = (
                r"\b" + re.escape(search_query) + r"\b"
                if case_sensitive
                else r"(?i)\b" + re.escape(search_query) + r"\b"
            )
            word_matches = re.finditer(pattern, line)

            for match in word_matches:
                char_start = match.start()
                char_end = match.end()

                abs_start = line_offsets[line_idx] + char_start
                abs_end = line_offsets[line_idx] + char_end
                ctx_start = max(0, abs_start - context_chars)
                ctx_end = min(len(text), abs_end + context_chars)
                context = text[ctx_start:ctx_end].replace("\n", " ").strip()
                if ctx_start > 0:
                    context = "..." + context
                if ctx_end < len(text):
                    context = context + "..."

                matches.append(
                    SearchMatch(
                        page=page_num,
                        line=line_idx + 1,
                        char_start=char_start,
                        char_end=char_end,
                        context=context,
                    )
                )
        else:
            pos = 0
            while True:
                pos = search_text.find(search_query, pos)
                if pos == -1:
                    break

                char_start = pos
                char_end = pos + len(search_query)

                abs_start = line_offsets[line_idx] + char_start
                abs_end = line_offsets[line_idx] + char_end
                ctx_start = max(0, abs_start - context_chars)
                ctx_end = min(len(text), abs_end + context_chars)
                context = text[ctx_start:ctx_end].replace("\n", " ").strip()
                if ctx_start > 0:
                    context = "..." + context
                if ctx_end < len(text):
                    context = context + "..."

                matches.append(
                    SearchMatch(
                        page=page_num,
                        line=line_idx + 1,
                        char_start=char_start,
                        char_end=char_end,
                        context=context,
                    )
                )

                pos = char_end

    return matches


def _search_page_text(
    page_text: str,
    page_num: int,
    query: str,
    case_sensitive: bool,
    whole_word: bool,
    context_chars: int,
) -> list[SearchMatch]:
    """Search a single page's text - designed to be called in parallel."""
    if page_text:
        return _search_in_text(
            page_text,
            query,
            page_num,
            case_sensitive,
            whole_word,
            context_chars,
        )
    return []


def _extract_page_text_with_ocr_fallback(page: fitz.Page, page_num: int) -> str:
    """Extract text from a page; use OCR fallback when page is image-only."""
    page_text = page.get_text("text") or ""
    if page_text.strip():
        return page_text
    # Try OCR for scanned/image-only pages
    if ocr_available():
        try:
            mat = fitz.Matrix(2, 2)  # 2x zoom for better OCR
            pix = page.get_pixmap(matrix=mat)
            img_bytes = pix.tobytes("png")
            ocr_text = ocr_page_image(img_bytes, format="PNG")
            if ocr_text:
                return ocr_text
        except Exception:
            pass
    return ""


def _extract_all_page_texts(pdf_path: str) -> list[tuple[int, str]]:
    """Extract text from all pages in a single PDF open. Returns list of (page_num, text)."""
    page_texts: list[tuple[int, str]] = []
    doc = fitz.open(pdf_path)
    try:
        for page_num in range(1, len(doc) + 1):
            try:
                page = doc[page_num - 1]
                page_text = _extract_page_text_with_ocr_fallback(page, page_num)
                page_texts.append((page_num, page_text))
            except Exception:
                page_texts.append((page_num, ""))
    finally:
        doc.close()
    return page_texts


def _search_sequential(
    pdf_path: str,
    total_pages: int,
    query: str,
    case_sensitive: bool,
    whole_word: bool,
    context_chars: int,
    max_results: int,
) -> list[SearchMatch]:
    """Sequential page processing for small PDFs."""
    all_matches: list[SearchMatch] = []

    doc = fitz.open(pdf_path)
    try:
        for page_num in range(1, total_pages + 1):
            try:
                page = doc[page_num - 1]
                page_text = _extract_page_text_with_ocr_fallback(page, page_num)

                if page_text:
                    page_matches = _search_in_text(
                        page_text,
                        query,
                        page_num,
                        case_sensitive,
                        whole_word,
                        context_chars,
                    )
                    all_matches.extend(page_matches)

                    if len(all_matches) >= max_results:
                        return all_matches[:max_results]
            except Exception:
                continue
    finally:
        doc.close()

    return all_matches


def _search_parallel(
    pdf_path: str,
    query: str,
    case_sensitive: bool,
    whole_word: bool,
    context_chars: int,
    max_results: int,
) -> list[SearchMatch]:
    """Parallel page processing for large PDFs.

    Extracts all page texts first (single PDF open), then parallelizes the search.
    """
    # Step 1: Extract all page texts with a single PDF open (I/O bound)
    page_texts = _extract_all_page_texts(pdf_path)

    # Step 2: Search in parallel across extracted texts (CPU bound)
    all_matches: list[SearchMatch] = []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(
                _search_page_text,
                page_text,
                page_num,
                query,
                case_sensitive,
                whole_word,
                context_chars,
            ): page_num
            for page_num, page_text in page_texts
        }

        for future in as_completed(futures):
            page_matches = future.result()
            all_matches.extend(page_matches)

    # Sort since parallel results are unordered
    all_matches.sort(key=lambda m: (m.page, m.line, m.char_start))
    return all_matches[:max_results]


@make_async_background
def search_pdf(
    file_path: Annotated[
        str,
        Field(
            description="Absolute path to the PDF file. Must start with '/' and end with '.pdf'."
        ),
    ],
    query: Annotated[
        str,
        Field(
            description="The text string to search for within the PDF. Must be non-empty."
        ),
    ],
    case_sensitive: Annotated[
        bool,
        Field(
            description="If True, match the exact letter casing of the query. Defaults to False (case-insensitive)."
        ),
    ] = False,
    whole_word: Annotated[
        bool,
        Field(
            description="If True, only match the query as a complete word (bounded by word boundaries). Defaults to False."
        ),
    ] = False,
    max_results: Annotated[
        int,
        Field(
            description="Maximum number of matches to return. Defaults to 100. Must be a positive integer."
        ),
    ] = 100,
    context_chars: Annotated[
        int,
        Field(
            description="Number of characters of context before and after each match. Defaults to 50."
        ),
    ] = 50,
) -> str:
    """Search for text occurrences across all pages of a PDF document.

    Extracts text from each page and performs substring or whole-word
    matching against the query. Uses parallel processing for PDFs with
    more than a few pages. Returns match count, positions (page, line,
    character offsets), and surrounding context for each hit.
    """

    # Validate inputs
    if not isinstance(file_path, str) or not file_path:
        return str(
            SearchResult(
                query=query or "", total_matches=0, error="File path is required"
            )
        )

    if not file_path.startswith("/"):
        return str(
            SearchResult(
                query=query or "", total_matches=0, error="File path must start with /"
            )
        )

    if not file_path.lower().endswith(".pdf"):
        return str(
            SearchResult(
                query=query or "", total_matches=0, error="File path must end with .pdf"
            )
        )

    if not isinstance(query, str) or not query:
        return str(
            SearchResult(
                query=query or "", total_matches=0, error="Search query is required"
            )
        )

    if not isinstance(max_results, int) or max_results < 1:
        max_results = 100

    if not isinstance(context_chars, int) or context_chars < 0:
        context_chars = 50

    # Resolve path with security check
    target_path, path_error = _resolve_under_root(file_path)
    if path_error:
        return str(SearchResult(query=query, total_matches=0, error=path_error))

    try:
        # Check file exists
        if not os.path.exists(target_path):
            return str(
                SearchResult(
                    query=query, total_matches=0, error=f"File not found: {file_path}"
                )
            )

        if not os.path.isfile(target_path):
            return str(
                SearchResult(
                    query=query, total_matches=0, error=f"Not a file: {file_path}"
                )
            )

        # Get total pages first
        doc = fitz.open(target_path)
        total_pages = len(doc)
        doc.close()

        # Use sequential for small PDFs, parallel for large ones
        if total_pages <= PARALLEL_THRESHOLD:
            all_matches = _search_sequential(
                target_path,
                total_pages,
                query,
                case_sensitive,
                whole_word,
                context_chars,
                max_results,
            )
        else:
            all_matches = _search_parallel(
                target_path,
                query,
                case_sensitive,
                whole_word,
                context_chars,
                max_results,
            )

        result = SearchResult(
            query=query, total_matches=len(all_matches), matches=all_matches, error=None
        )

        return str(result)

    except Exception as exc:
        return str(
            SearchResult(
                query=query, total_matches=0, error=f"Search failed: {repr(exc)}"
            )
        )
