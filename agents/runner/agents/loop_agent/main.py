"""
Loop Agent implementation.

This is a simple agent that runs in a loop, calling the LLM and executing tool calls
until the LLM returns a response without tool calls (indicating task completion).
"""

import asyncio
import time
from typing import Any

from fastmcp import Client as FastMCPClient
from litellm import Choices
from litellm.exceptions import Timeout
from litellm.experimental_mcp_client import call_openai_tool, load_mcp_tools
from litellm.files.main import ModelResponse
from loguru import logger
from openai.types.chat.chat_completion_tool_param import ChatCompletionToolParam

from runner.agents.models import (
    AgentRunInput,
    AgentStatus,
    AgentTrajectoryOutput,
    LitellmAnyMessage,
    LitellmInputMessage,
    LitellmOutputMessage,
)
from runner.utils.error import is_fatal_mcp_error, is_system_error
from runner.utils.llm import generate_response
from runner.utils.mcp import build_mcp_gateway_schema, content_blocks_to_messages
from runner.utils.usage import UsageTracker


def finalize_answer(final_answer: str | None = None) -> str | None:
    logger.bind(message_type="final_answer").info(final_answer)
    return final_answer


class LoopAgent:
    """
    A simple loop-based agent that calls the LLM and executes tool calls
    until the task is complete.
    """

    def __init__(self, run_input: AgentRunInput):
        self.trajectory_id: str = run_input.trajectory_id
        self.model: str = run_input.orchestrator_model
        self.messages: list[LitellmAnyMessage] = list(run_input.initial_messages)

        if run_input.mcp_gateway_url is None:
            raise ValueError("MCP gateway URL is required for loop agent")

        # Build MCP client for gateway connection
        self.mcp_client = FastMCPClient(
            build_mcp_gateway_schema(
                run_input.mcp_gateway_url,
                run_input.mcp_gateway_auth_token,
            )
        )

        self._finalized: bool = False
        self.tools: list[ChatCompletionToolParam] = []

        # Agent config values (with defaults)
        config = run_input.agent_config_values
        self.tool_call_timeout: int = config.get("tool_call_timeout", 60)
        self.llm_response_timeout: int = config.get("llm_response_timeout", 600)
        self.max_steps: int = config.get("max_steps", 100)
        self.timeout: int = config.get("timeout", 10800)  # 3 hours

        self.extra_args: dict[str, Any] = run_input.orchestrator_extra_args or {}

        self.current_step: int = 0
        self.start_time: float | None = None
        self.status: AgentStatus = AgentStatus.PENDING
        self._usage_tracker: UsageTracker = UsageTracker()

    async def _initialize_tools(self) -> None:
        """Load available tools from the MCP gateway."""
        async with self.mcp_client as client:
            tools: list[ChatCompletionToolParam] = await load_mcp_tools(
                client.session, format="openai"
            )  # pyright: ignore[reportAssignmentType]

        logger.bind(
            message_type="configure",
            payload=[tool.get("function").get("name") for tool in tools],
        ).info(f"Loaded {len(tools)} MCP tools")
        self.tools = tools

    async def step(self):
        """Execute a single step of the agent loop."""
        self.current_step += 1

        try:
            response: ModelResponse = await generate_response(
                self.model,
                self.messages,
                self.tools,
                self.llm_response_timeout,
                self.extra_args,
                trajectory_id=self.trajectory_id,
            )
        except Timeout:
            logger.bind(message_type="response").error(
                "Response timed out, continuing with next step"
            )
            return
        except Exception as e:
            logger.bind(message_type="response").error(
                f"Error generating response: {repr(e)}"
            )
            raise e

        self._usage_tracker.track(response)
        logger.debug(f"Response: {response}")

        choices = response.choices

        if not choices or not isinstance(choices[0], Choices):
            logger.bind(message_type="step").warning(
                "LLM returned invalid/empty choices, prompting to continue"
            )
            self.messages.append(
                LitellmOutputMessage(
                    role="user",
                    content="continue",
                )
            )
            return

        response_message = LitellmOutputMessage.model_validate(choices[0].message)
        tool_calls = getattr(response_message, "tool_calls", None)

        if getattr(response_message, "reasoning_content", None):
            logger.bind(message_type="reasoning").info(
                response_message.reasoning_content
            )

        if getattr(response_message, "content", None) and tool_calls:
            logger.bind(message_type="response").info(response_message.content)

        if getattr(response_message, "thinking_blocks", None):
            if isinstance(response_message.thinking_blocks, list):
                for thinking_block in response_message.thinking_blocks:
                    if thinking_block.get("thinking"):
                        logger.bind(message_type="thinking").debug(
                            thinking_block.get("thinking")
                        )

        self.messages.append(response_message)

        if tool_calls:
            deferred_image_messages: list[LitellmInputMessage] = []
            async with self.mcp_client as client:
                for tool_call in tool_calls:
                    name = tool_call.function.name

                    tool_logger = logger.bind(
                        ref=tool_call.id,
                        name=name,
                    )

                    tool_logger.bind(
                        message_type="tool_call", payload=tool_call.function.arguments
                    ).info(f"Calling tool {name}")

                    tool_result_logger = tool_logger.bind(message_type="tool_result")

                    try:
                        call_result = await asyncio.wait_for(
                            call_openai_tool(client.session, tool_call),
                            timeout=self.tool_call_timeout,
                        )
                    except TimeoutError:
                        tool_result_logger.error(f"Tool call {name} timed out")
                        self.messages.append(
                            LitellmOutputMessage(
                                role="tool",
                                tool_call_id=tool_call.id,
                                name=tool_call.function.name,
                                content="Tool call timed out",
                            )
                        )
                        continue
                    except Exception as e:
                        if is_fatal_mcp_error(e):
                            tool_result_logger.error(
                                f"Fatal MCP error, ending run: {repr(e)}"
                            )
                            self.messages.append(
                                LitellmOutputMessage(
                                    role="tool",
                                    tool_call_id=tool_call.id,
                                    name=tool_call.function.name,
                                    content=f"Fatal error: {e}",
                                )
                            )
                            raise
                        tool_result_logger.error(
                            f"Error calling tool {name}: {repr(e)}"
                        )
                        self.messages.append(
                            LitellmOutputMessage(
                                role="tool",
                                tool_call_id=tool_call.id,
                                name=tool_call.function.name,
                                content=f"Error calling tool: {repr(e)}",
                            )
                        )
                        continue

                    if not call_result.content:
                        tool_result_logger.error(
                            f"Call result for {name} is not valid: {call_result.content}"
                        )
                        self.messages.append(
                            LitellmOutputMessage(
                                role="tool",
                                tool_call_id=tool_call.id,
                                name=tool_call.function.name,
                                content=f"Call result is not valid, received {call_result.content}",
                            )
                        )
                        continue

                    messages = content_blocks_to_messages(
                        call_result.content,
                        tool_call.id,
                        tool_call.function.name or "unknown",
                        self.model,
                        deferred_image_messages=deferred_image_messages,
                    )

                    tool_result_logger.bind(
                        payload=[result.model_dump() for result in call_result.content],
                    ).info(f"Tool {name} called successfully")

                    self.messages.extend(messages)
            self.messages.extend(deferred_image_messages)
        else:
            # No tool calls = task complete
            self._finalized = True
            finalize_answer(
                response_message.content if response_message.content else "No content"
            )

    def _build_output(self) -> AgentTrajectoryOutput:
        return AgentTrajectoryOutput(
            messages=list(self.messages),
            status=AgentStatus(self.status),
            time_elapsed=time.time() - self.start_time if self.start_time else 0,
            usage=self._usage_tracker.to_dict(),
        )

    async def run(self) -> AgentTrajectoryOutput:
        """Run the agent loop until completion or timeout."""
        try:
            async with asyncio.timeout(self.timeout):
                with logger.contextualize(model=self.model):
                    logger.bind(message_type="configure").info(
                        f"Starting agent loop with model {self.model}"
                    )

                    await self._initialize_tools()

                    logger.bind(message_type="configure").info(
                        "\n".join(
                            f"{m['role'].capitalize()}: {m.get('content')}"
                            for m in self.messages
                        )
                    )

                    logger.info("Starting agent loop")
                    self.start_time = time.time()
                    self.status = AgentStatus.RUNNING

                    for i in range(self.max_steps):
                        if self._finalized:
                            logger.info(f"Agent loop was finalized after {i + 1} steps")
                            break
                        logger.bind(message_type="step").info(f"Starting step {i + 1}")
                        await self.step()

                    if not self._finalized:
                        logger.error(
                            f"Agent loop was not finalized after {self.max_steps} steps"
                        )
                        self.status = AgentStatus.FAILED
                    else:
                        self.status = AgentStatus.COMPLETED

                    return self._build_output()

        except TimeoutError:
            logger.error(f"Agent run timed out after {self.timeout} seconds")
            self.status = AgentStatus.ERROR
            return self._build_output()

        except asyncio.CancelledError:
            logger.error("Agent run cancelled")
            self.status = AgentStatus.CANCELLED
            return self._build_output()

        except Exception as e:
            logger.error(f"Error running agent: {repr(e)}")
            if is_system_error(e):
                self.status = AgentStatus.ERROR
            else:
                self.status = AgentStatus.FAILED
            return self._build_output()


async def run(run_input: AgentRunInput) -> AgentTrajectoryOutput:
    """
    Entry point for the loop agent.

    Args:
        run_input: The input configuration for the agent run

    Returns:
        AgentTrajectoryOutput with status, messages, and metrics
    """
    agent = LoopAgent(run_input)
    return await agent.run()
