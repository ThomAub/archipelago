"""Token usage tracking for agent LLM calls."""

from typing import Any

from litellm.files.main import ModelResponse


class UsageTracker:
    """Accumulates token usage across multiple LLM calls during agent execution."""

    def __init__(self) -> None:
        self.prompt_tokens: int = 0
        self.completion_tokens: int = 0
        self.final_answer_tokens: int = 0

    def track(self, response: ModelResponse) -> None:
        """Extract and accumulate usage from a ModelResponse."""
        usage = getattr(response, "usage", None)
        if usage is None:
            return

        self.prompt_tokens += getattr(usage, "prompt_tokens", 0) or 0
        self.completion_tokens += getattr(usage, "completion_tokens", 0) or 0
        self.final_answer_tokens = getattr(usage, "completion_tokens", 0) or 0

    def track_from_dict(self, response_dict: dict[str, Any]) -> None:
        """Extract and accumulate usage from a response dictionary (e.g., Responses API).

        Handles both OpenAI Responses API format and standard completion format.
        """
        usage = response_dict.get("usage")
        if usage is None:
            return

        prompt_tokens = usage.get("prompt_tokens") or usage.get("input_tokens") or 0
        completion_tokens = (
            usage.get("completion_tokens") or usage.get("output_tokens") or 0
        )

        self.prompt_tokens += prompt_tokens
        self.completion_tokens += completion_tokens
        self.final_answer_tokens = completion_tokens

    def to_dict(self) -> dict[str, int]:
        """Return accumulated usage as a dict for AgentTrajectoryOutput."""
        return {
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "total_tokens": self.prompt_tokens + self.completion_tokens,
            "final_answer_tokens": self.final_answer_tokens,
        }
