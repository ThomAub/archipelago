"""Snapshot DBs helper - extracts and connects to SQLite databases."""

import io
import sqlite3
import tempfile
import zipfile
from typing import Any

from loguru import logger

from runner.models import AgentTrajectoryOutput

# NOTE: Temp files and DB connections are cleaned up when process exits.
# In Modal, each grading run is a separate process, so cleanup is automatic.
# For long-running processes, connections dict includes temp_path for manual cleanup.


async def snapshot_dbs_helper(
    initial_snapshot_bytes: io.BytesIO,
    final_snapshot_bytes: io.BytesIO,
    trajectory: AgentTrajectoryOutput,
) -> dict[str, Any]:
    """
    Extract SQLite databases from final snapshot.

    Returns dict of {alias: connection_info} for each .db file found.

    Note: DB connections and temp files are left open for the duration
    of the process. In Modal, each grading run is a separate process that
    exits after completion, automatically cleaning up resources.

    Port of: verifier module's DB connection logic
    """
    connections = {}

    # Reset BytesIO position for reading
    final_snapshot_bytes.seek(0)

    with zipfile.ZipFile(final_snapshot_bytes, "r") as final_zip:
        # Find all .db files
        db_files = [f for f in final_zip.namelist() if f.endswith(".db")]

        for db_file in db_files:
            # Extract database bytes
            db_bytes = final_zip.read(db_file)

            # Write to temp file (SQLite needs file path)
            temp_file = tempfile.NamedTemporaryFile(
                suffix=".db", delete=False, mode="wb"
            )
            temp_file.write(db_bytes)
            temp_file.flush()
            temp_file.close()

            # Create SQLite connection
            # Note: Connection and temp file will be cleaned up when process exits
            conn = sqlite3.connect(temp_file.name)

            # Generate unique alias using full path to avoid collisions
            # e.g., "data/sales.db" → "data_sales"
            # e.g., "backup/sales.db" → "backup_sales"
            path_parts = db_file.replace(".db", "").replace("/", "_").replace("\\", "_")
            alias = path_parts

            # Warn about collision if alias already exists
            if alias in connections:
                logger.warning(
                    f"Database alias collision: '{alias}' already exists. "
                    f"Previous: {connections[alias]['path']}, New: {db_file}"
                )

            connections[alias] = {
                "connection": conn,
                "path": db_file,
                "temp_path": temp_file.name,
            }

    # Reset BytesIO position after use for potential reuse
    final_snapshot_bytes.seek(0)

    return connections
